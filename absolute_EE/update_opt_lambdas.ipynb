{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f373647c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, re\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "from scipy.interpolate import interp1d\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def get_coul_vdW_lambdas(mdpfile):\n",
    "    \"\"\"Given an *.mdp file as input, extract the values of coul-lambdas and vdw-lambdas\n",
    "    \n",
    "    RETURNS\n",
    "    coul_lambdas    - numpy array of coul-lambdas\n",
    "    vdw_lambdas     - numpy array of vdw-lambdas\n",
    "    \n",
    "    NOTE: for some specific rpojects, the lambda=0 state is fully coupled,  and lambda=1 is fully uncoupled:         \n",
    "              couple-lambda0         = vdw-q\n",
    "              couple-lambda1         = none              \n",
    "          That means that *first* the coulomb gets turned off, *then* the vdW:\n",
    "          \n",
    "    coul-lambdas         = 0.0 0.020 0.040 0.061 0.081 ... 0.979 1.0 1.000 1.000 1.000 1.000 ... 1.000 1.0\n",
    "    vdw-lambdas          = 0.0 0.000 0.000 0.000 0.000 ... 0.000 0.0 0.020 0.040 0.061 0.081 ... 0.979 1.0\n",
    "    \"\"\"\n",
    "\n",
    "    fin = open(mdpfile,'r')\n",
    "    lines = fin.readlines()\n",
    "    fin.close()\n",
    "\n",
    "    coul_lambdas, vdw_lambdas = None, None\n",
    "\n",
    "    for line in lines:\n",
    "        if line.count('coul-lambdas'):\n",
    "            coul_string = line.split('=')[1].strip()\n",
    "            coul_lambdas = np.array([float(s) for s in coul_string.split()])\n",
    "        elif line.count('vdw-lambdas'):\n",
    "            vdw_string = line.split('=')[1].strip()\n",
    "            vdw_lambdas = np.array([float(s) for s in vdw_string.split()])\n",
    "        elif line.count('restraint-lambdas'):\n",
    "            restraint_string = line.split('=')[1].strip()\n",
    "            restraint_lambdas = np.array([float(s) for s in restraint_string.split()])\n",
    "\n",
    "    return coul_lambdas, vdw_lambdas, restraint_lambdas\n",
    "\n",
    "def get_dhdl_data(dhdl_xvgfile, verbose=True):\n",
    "\n",
    "    r\"\"\"Read and parse the information in the dhdl file.\n",
    "    \n",
    "    RETURNS\n",
    "    time_in_ps      - time in ps (1D np.array)\n",
    "    thermo_states   - thermodynamic state indices (1D np.array)\n",
    "    dhdl            - delta_Uij (np.array of shape (N,K))\n",
    "                      where N is snapshots and K is number of thermodynamic states\n",
    "    \n",
    "    NOTES!!!\n",
    "    ----> In ABSOLUTE binding free energy calcultions,\n",
    "    \n",
    "    time         ---> Column 0 is time in ps.                         \n",
    "    thermo_index ---> Column 1 = @ s0 legend \"Thermodynamic state\"\n",
    "                      Column 2 = @ s1 legend \"Total Energy (kJ/mol)\"\n",
    "                      Column 3 = @ s2 legend \"dH/d\\\\xl\\\\f{} fep-lambda = 0.0000\"\n",
    "                      Column 4 = @ s3 legend \"dH/d\\\\xl\\\\f{} coul-lambda = 0.0000\"\n",
    "                      Column 5 = @ s4 legend \"dH/d\\\\xl\\\\f{} vdw-lambda = 0.0000\"\n",
    "    dU_ij starts      Column 6 = @ s5 legend \"\\\\xD\\\\f{}H \\\\xl\\\\f{} to (0.0000, 0.0000, 0.0000)\"\n",
    "                      Column 7 = @ s6 legend \"\\\\xD\\\\f{}H \\\\xl\\f{} to (0.0000, 0.0200, 0.0000)\"\n",
    "                      Column 8 = @ s7 legend \"\\\\xD\\\\f{}H \\\\xl\\\\f{} to (0.0000, 0.0400, 0.0000)\"\n",
    "    \n",
    "    \n",
    "    ----> In RELATIVE binding free energy calcultions,\n",
    "    time         ---> Column 0 is time in ps.                         \n",
    "    thermo_index ---> Column 1 = @ s0 legend \"Thermodynamic state\"\n",
    "                      Column 2 = @ s1 legend \"Total Energy (kJ/mol)\"\n",
    "                      Column 3 = @ s2 legend \"dH/d\\xl\\f{} fep-lambda = 0.0000\"\n",
    "    \n",
    "    dU_ij starts ---> Column 4 = @ s3 legend \"\\xD\\f{}H \\xl\\f{} to 0.0000\n",
    "                      Column 5 = @ s4 legend \"\\xD\\f{}H \\xl\\f{} to 0.0020\n",
    "                      Column 6 = @ s5 legend \"\\xD\\f{}H \\xl\\f{} to 0.0040\n",
    "    \"\"\"\n",
    "    \n",
    "    assert os.path.exists(dhdl_xvgfile)\n",
    "\n",
    "    # Read and parse the file\n",
    "    fin = open(dhdl_xvgfile,'r')\n",
    "    lines = fin.readlines()\n",
    "    fin.close()\n",
    "\n",
    "    dhdl_column_start = None\n",
    "    # Read to headers to find which column starts the dhdl data\n",
    "    for line in lines:\n",
    "        # Looking for line like this: \"@ s5 legend \"\\xD\\f{}H \\xl\\f{} to (0.0000, 0.0000, 0.0000)\"\n",
    "        # or Looking for line like this: \"@ s3 legend \"\\xD\\f{}H \\xl\\f{} to 0.0000\"\n",
    "        if line.count('\"\\\\xD\\\\f{}H') > 0:\n",
    "            dhdl_column_start = int(line.split(' ')[1].replace('s','')) + 1\n",
    "            break\n",
    "    if verbose:\n",
    "        print('dhdl data starts at column:', dhdl_column_start)\n",
    "\n",
    "    # Get rid of all the header lines\n",
    "    i = 0\n",
    "    while i < len(lines):\n",
    "        if (lines[i][0] == '#') or (lines[i][0] == '@'):\n",
    "            lines.pop(i)\n",
    "        else:\n",
    "            i+=1\n",
    "            \n",
    "    # find the correct number of entries from the first line\n",
    "    ncols = len(lines[0].strip().split())\n",
    "    #print(lines[0])\n",
    "    #print('ncols', ncols)\n",
    "\n",
    "    time_in_ps, dhdl, thermo_states = [], [], []\n",
    "    for line in lines:\n",
    "        line_data_list = [float(s) for s in line.strip().split()]\n",
    "\n",
    "        # Skip line if it doesn't have the correct number of entries (sometimes the I/O gets cutoff when writing the dhdl.xvg in it corrupts the data)\n",
    "        if len(line_data_list) == ncols:\n",
    "            time_in_ps.append(line_data_list[0])\n",
    "            thermo_states.append(line_data_list[1])\n",
    "            dhdl.append(line_data_list[dhdl_column_start:])\n",
    "\n",
    "    time_in_ps = np.array(time_in_ps)\n",
    "    dhdl = np.array(dhdl)\n",
    "    thermo_states = np.array([int(x) for x in thermo_states])\n",
    "\n",
    "    return time_in_ps, thermo_states, dhdl\n",
    "\n",
    "def get_pull_x(pull_xvgfile):\n",
    "    assert os.path.exists(pull_xvgfile)\n",
    "\n",
    "    # Read and parse the file\n",
    "    fin = open(pull_xvgfile,'r')\n",
    "    lines = fin.readlines()\n",
    "    fin.close()\n",
    "    for x,line in enumerate(lines):\n",
    "        if '0.0000' in line:\n",
    "            break\n",
    "    pull_x = [[float(y) for y in line.split()[1:]] for line in lines[x:]]\n",
    "    return pull_x\n",
    "\n",
    "def estimate_sigmas(dhdl, thermo_states, plot_data=True):\n",
    "    \"\"\"Using as input the Delta_U_ij energies from the dhdl array, \n",
    "    estimate the standard deviations P(U_{i-->i+1}) for neighboring ensembles.\n",
    "    \n",
    "    RETURNS\n",
    "    sigmas   - a np.array() of standard deviations P(U_{i-->i+1}).\n",
    "    \"\"\"\n",
    "\n",
    "    nlambdas = dhdl.shape[1]\n",
    "    Delta_uij_values = []\n",
    "    sigmas = []\n",
    "    \n",
    "    if plot_data:\n",
    "        plt.figure(figsize=(6, 12))\n",
    "    \n",
    "    for j in range(nlambdas-1):\n",
    "\n",
    "        ##transitions from state 0 to 1 or 1 to 2, or 2 to 3 .... \n",
    "        Ind_i = (thermo_states == j)\n",
    "        delta_u_ij = dhdl[Ind_i, j+1]       ##only for neighbored ensembles\n",
    "\n",
    "        #Delta_uij_values.append(delta_u_ij)\n",
    "\n",
    "        mu, sigma = scipy.stats.norm.fit(delta_u_ij)\n",
    "        sigmas.append(sigma)\n",
    "        \n",
    "        delta_u_bins = np.arange(-100., 100., 0.2)\n",
    "        counts, bin_edges = np.histogram(delta_u_ij, bins=delta_u_bins)\n",
    "        counts = counts/counts.sum() # normalize\n",
    "        bin_centers = (bin_edges[0:-1] + bin_edges[1:])/2.0\n",
    "\n",
    "        if plot_data:\n",
    "            plt.subplot(nlambdas-1, 1, j+1)\n",
    "            plt.step(bin_centers, counts, label='$\\Delta u_{%d \\\\rightarrow %d} \\sigma$=%.2f'%(j,j+1,sigma))\n",
    "            #plt.xlabel('$\\Delta u_{%d \\\\rightarrow %d}$'%(j, j+1))\n",
    "            plt.legend(loc='best')\n",
    "\n",
    "    if plot_data:\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{path}/deltas.png')\n",
    "        plt.close()\n",
    "\n",
    "    return np.array(sigmas)\n",
    "\n",
    "\n",
    "def opt_lambdas(sigmas, cal_type, make_plots=False):   #cal_type = 'absolute'(having coul and vdw) or 'relative' (only having fep lambdas)\n",
    "\n",
    "    print('sigmas', sigmas)\n",
    "                  \n",
    "    ### Lambda optimization\n",
    "    dx = sigmas                 #according to the equation (VAV: k is set to 1)\n",
    "\n",
    "    x_values = np.cumsum(dx)    # convert to a list of x values of separated harmonic potentials\n",
    "    x_values = np.array(np.concatenate([[0], x_values]))    # add a zero corresponding to lambda0 = 0.0\n",
    "    print('x_values', x_values)\n",
    "\n",
    "    if make_plots:\n",
    "        plt.figure(figsize=(12,6))\n",
    "\n",
    "                \n",
    "    lambda_values = lambdas         #not inclduing the first one, lambda_0 \n",
    "\n",
    "    x_observed = lambda_values      #not inclduing the first one, lambda_0\n",
    "    y_observed = x_values\n",
    "                \n",
    "    if make_plots:\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.plot(x_observed, y_observed, 'ro', label = 'data')\n",
    "        #plt.semilogy(x_observed, y_observed, 'ro', label = 'data')\n",
    "     #y_spl = CubicSpline(x_observed, y_observed)#, s=0,k=4)  \n",
    "\n",
    "    dupes = [i for i in range(1,len(y_observed)) if y_observed[i-1] == y_observed[i]]\n",
    "    if dupes:\n",
    "        print(f'There are degenerate ensembles in your dhdl file. If you wish to remove them, uncomment the lines under this warning.'')\n",
    "        #x_observed = np.delete(x_observed, dupes)\n",
    "        #y_observed = np.delete(y_observed, dupes)'\n",
    "    try:\n",
    "        y_spl = UnivariateSpline(x_observed, y_observed, s=0, k=3)\n",
    "    except Exception as e:\n",
    "        print(e, \"Failed to make y_spl...\")\n",
    "    x_range = np.linspace(x_observed[0], x_observed[-1], 1000)\n",
    "        \n",
    "    if make_plots:\n",
    "        plt.plot(x_range, y_spl(x_range), label=\"spline\")   # for UnivariateSpline\n",
    "        ## plt.plot(x_observed, y_spl(x_observed), label=\"spline\") # for CubicSpline\n",
    "        plt.legend()\n",
    "        plt.xlabel('lambda')\n",
    "        plt.ylabel('x values')\n",
    "            \n",
    "        plt.subplot(1,2, 2)   #derivative plot   \n",
    " \n",
    "    y_spl_1d = y_spl.derivative(n=1)    #n=1 , means the first order derivative\n",
    "    # y_spl_1d = y_spl(x_observed, 1)  # first derivative of Cubic spline\n",
    "                \n",
    "    if make_plots:\n",
    "        plt.plot(x_range, y_spl_1d(x_range), '-')\n",
    "        plt.plot(x_observed, y_spl_1d(x_observed), '.')\n",
    "        plt.ylabel('dx/dlambda')\n",
    "                         \n",
    "                \n",
    "    # Let's try a steepest descent algorithm: run the algorithm some fixed number of steps, or until some tolerance is reached\n",
    "    nsteps = 1000000\n",
    "    tol = 1e-8  # stop if the lambdas dont change within this tolerance\n",
    "\n",
    "    alpha = 2e-4  # gradient descent step size\n",
    "    max_del_lambda = 0.0001   # the minimization step limited to this as a maximum change\n",
    "\n",
    "    VERBOSE = False\n",
    "    print_every = 25000\n",
    "\n",
    "    nlambdas = len(lambda_values)\n",
    "    print('lambda_values', lambda_values)\n",
    "    old_lambdas = np.array(lambda_values)\n",
    "    traj_lambdas = np.zeros( (nlambdas,nsteps) )\n",
    "    for step in range(nsteps):\n",
    "        # store the trajectory of lambdas\n",
    "        traj_lambdas[:,step] = old_lambdas\n",
    "        if VERBOSE:\n",
    "            print('step', step, old_lambdas)\n",
    "\n",
    "        # perform a steepest descent step\n",
    "        new_lambdas = np.zeros( old_lambdas.shape )\n",
    "        del_lambdas = np.zeros( old_lambdas.shape )\n",
    "        del_lambdas[0] = 0.0   # fix the \\lambda = 0 endpoint\n",
    "        del_lambdas[nlambdas-1] = 0.0  # fix the \\lambda = 1 endpoint\n",
    "                \n",
    "        if False:  # do in a loop (SLOW!) \n",
    "            for i in range(1, (nlambdas-1)):\n",
    "                del_lambdas[i] = -1.0*alpha*2.0*y_spl_1d(old_lambdas[i])*( 2.0*y_spl(old_lambdas[i]) - y_spl(old_lambdas[i-1]) - y_spl(old_lambdas[i+1]))\n",
    "        else:   # do as a vector operation (FAST!) \n",
    "            y_all = y_spl(old_lambdas)\n",
    "            yh, yi, yj = y_all[0:nlambdas-2], y_all[1:nlambdas-1], y_all[2:nlambdas]\n",
    "            del_lambdas[1:nlambdas-1] = -1.0*alpha*2.0*y_spl_1d(old_lambdas[1:nlambdas-1])*( 2.0*yi - yh - yj)\n",
    "        if abs(np.max(del_lambdas)) > max_del_lambda:\n",
    "            del_lambdas[1:nlambdas-1] = del_lambdas[1:nlambdas-1]*max_del_lambda/np.max(del_lambdas)\n",
    "        new_lambdas = old_lambdas + del_lambdas\n",
    "\n",
    "        # record the average change in the lambdas \n",
    "        del_lambdas = np.abs(old_lambdas - new_lambdas).mean()\n",
    "        if step % print_every == 0:\n",
    "            print('step', step, 'del_lambdas', del_lambdas)\n",
    "        if del_lambdas < tol:\n",
    "            print('Tolerance has been reached: del_lambdas =', del_lambdas, '< tol =', tol)\n",
    "            break\n",
    "\n",
    "        old_lambdas = new_lambdas\n",
    "                \n",
    "    if make_plots:\n",
    "        # Plot the results\n",
    "        plt.figure(figsize=(12,4))\n",
    "\n",
    "        plt.subplot(1,2,1)\n",
    "        for i in range(nlambdas):\n",
    "            plt.plot(range(step), traj_lambdas[i,0:step], '-')\n",
    "        plt.xlabel('step')\n",
    "        plt.ylabel('lambda values')\n",
    "\n",
    "        plt.subplot(1,2,2)\n",
    "        for i in range(nlambdas):\n",
    "            plt.plot(range(step), y_spl(traj_lambdas[i,0:step]), '-')\n",
    "        plt.xlabel('step')\n",
    "        plt.ylabel('x values')\n",
    "        plt.savefig(f'{path}/traj_lambdas.png')\n",
    "        plt.close()                \n",
    "\n",
    "        plt.figure(figsize=(12,4))\n",
    "\n",
    "        plt.subplot(2,1,1)\n",
    "        plt.plot(x_range, y_spl(x_range), 'b-', label=\"spline\")\n",
    "        plt.plot(lambda_values, y_spl(np.array(lambda_values)), 'r.', label=\"old lambdas\")\n",
    "        for value in lambda_values:\n",
    "            plt.plot([value, value], [0, y_spl(value)], 'r-')\n",
    "        plt.legend()\n",
    "        plt.xlabel('lambda')\n",
    "        plt.ylabel('x values')\n",
    "        plt.title('old lambdas')\n",
    "\n",
    "        plt.subplot(2,1,2)\n",
    "        plt.plot(x_range, y_spl(x_range), 'b-', label=\"spline\")\n",
    "        plt.plot(new_lambdas, y_spl(new_lambdas), 'g.', label=\"new lambdas\")\n",
    "        for value in new_lambdas:\n",
    "            plt.plot([value, value], [0, y_spl(value)], 'g-')\n",
    "        plt.legend()\n",
    "        plt.xlabel('lambda')\n",
    "        plt.ylabel('x values')\n",
    "        plt.title('new lambdas')\n",
    "        plt.savefig(f'{path}/lambda_values')         \n",
    "                \n",
    "    if cal_type == 'absolute':\n",
    "        # Finally, we transform the [0,2] coul+vdW interval back to separate coul_lambdas and vdw_lambdas\n",
    "        new_rest_lambdas = np.minimum(new_lambdas, np.ones(new_lambdas.shape))\n",
    "        new_coul_lambdas  = np.maximum(new_lambdas, np.ones(new_lambdas.shape)) - 1\n",
    "        new_vdw_lambdas  = np.maximum([x-1 for x in new_coul_lambdas], np.zeros(new_lambdas.shape))\n",
    "        new_coul_lambdas = np.minimum(new_coul_lambdas, np.ones(new_lambdas.shape))\n",
    "        \n",
    "        # print out the new lambdas as if they were in an mdp file\n",
    "        outstring = 'rest-lambdas    = ' + \" \".join(['%1.4f'%lam for lam in new_rest_lambdas])\n",
    "        outstring += '\\ncoul-lambdas    = ' + \" \".join(['%1.4f'%lam for lam in new_coul_lambdas])\n",
    "        outstring += '\\nvdw-lambdas     = ' + \" \".join(['%1.4f'%lam for lam in new_vdw_lambdas]) +'\\n'\n",
    "        print(outstring)\n",
    "        with open(f'{path}/lambdas.txt', 'w') as f:\n",
    "            f.write(outstring)\n",
    "    \n",
    "    if cal_type == 'relative':\n",
    "        # finally, print out new fep-lambdas\n",
    "        outstring = 'fep_lambdas               =' + \" \".join(['%1.4f'%lam for lam in new_lambdas])\n",
    "        print (outstring)\n",
    "        with open(f'{path}/lambdas.txt', 'w') a f:\n",
    "            f.write(outstring)\n",
    "            \n",
    "    return new_coul_lambdas, new_vdw_lambdas, new_rest_lambdas\n",
    "\n",
    "\n",
    "for prefix in ['RL/pre-opt','RL/post-opt']:\n",
    "    for run in [3,4,5,6,7]: #range(8):\n",
    "        path = f'{prefix}/RUN{run}'\n",
    "        mdpfile      = f'{path}/prod.mdp'\n",
    "        dhdl_xvgfile = f'{path}/dhdl.xvg'\n",
    "        pull_xvgfile = f'{path}/pullx.xvg'\n",
    "        cal_type = 'absolute'      # relative or absolute\n",
    "        optimize = True\n",
    "        path = f'{prefix}/RUN{run}'\n",
    "\n",
    "        try:\n",
    "          if cal_type == 'absolute':\n",
    "            coul_lambdas, vdw_lambdas, restraint_lambdas = get_coul_vdW_lambdas(mdpfile)\n",
    "            pull_x = get_pull_x(pull_xvgfile)\n",
    "            # We map each [0,1] set of values to the interval [0,2] by elemenet-wise summing of the two sets of values\n",
    "            lambdas = coul_lambdas + vdw_lambdas + restraint_lambdas\n",
    "\n",
    "            time_in_ps, thermo_states, dhdl = get_dhdl_data(dhdl_xvgfile)\n",
    "            min_len = min([len(dhdl), len(thermo_states),len(pull_x)])\n",
    "            dhdl = dhdl[:min_len]\n",
    "            thermo_states = thermo_states[:min_len]\n",
    "            \n",
    "            # uncomment if restraints are not accounted for in dhdl\n",
    "            #pull_x = pull_x[:min_len]\n",
    "            #for frame in range(len(dhdl)):\n",
    "            #    dhdl[frame] = [dhdl[frame][x] + 0.5*k*(restraint_lambdas[thermo_states[frame]] - restraint_lambdas[x]) * np.sum([pull_x[frame][y]**2 for y in range(len(pull_x[frame]))]) for x in range(len(dhdl[frame]))]\n",
    "            np.save(f'{path}/dhdl.npy',dhdl)\n",
    "            np.save(f'{path}/itraj.npy',thermo_states)\n",
    "            \n",
    "            if optimize:\n",
    "                sigmas = estimate_sigmas(dhdl, thermo_states, plot_data=True)\n",
    "                coul, vdw, rest = opt_lambdas(sigmas, cal_type, make_plots=True)\n",
    "                np.save(f'{path}/lambdas.npy', [coul, vdw])\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(e, f\"Failed to optimize lambdas for {path}\")\n",
    "            continue      "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
