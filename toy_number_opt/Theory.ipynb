{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6835bdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a09daa",
   "metadata": {},
   "source": [
    "Assume a system of a particle defined by position *x*. Iy underoes a random walk by MCMC under metropolis-hastings acceptance criteria;\n",
    "\n",
    "$$A(x',x) = -1*min(1,exp(U(x')- U(x)))$$\n",
    "\n",
    ", experiencing harmonic bias potentials at positions $\\lambda_i$ defined as;\n",
    "\n",
    "$$U(x) = \\frac{k}{2}(x-x_i)^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1d87ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_sigmas(lambdas,trans):\n",
    "    nlambdas = len(lambdas)\n",
    "    thermo_states = np.arange(nlambdas) \n",
    "    Delta_uij_values = []     \n",
    "    sigmas = []\n",
    "       \n",
    "    for j in range(nlambdas-1):\n",
    "    \n",
    "        ## transitions from state 0 to 1 or 1 to 2, or 2 to 3 .... \n",
    "\n",
    "        Ind = (thermo_states == j)\n",
    "        delta_u_ij = trans[Ind, j+1]     # forward delta_u only for neighbored ensembles\n",
    "\n",
    "        Ind2 = (thermo_states == (j+1))\n",
    "        delta_u_ji = trans[Ind2, j]       # forward delta_u only for neighbored ensembles\n",
    "\n",
    "        print ('lambda index=', j)\n",
    "        #print ('delta_u_ij.shape=', delta_u_ij.shape)\n",
    "      \n",
    "        #Delta_uij_values.append(delta_u_ij)\n",
    "\n",
    "        ### VAV debug\n",
    "        print('Are any delta_u_ij values nan?')\n",
    "        print(delta_u_ij)\n",
    "        print('Are any delta_u_ji values nan?')\n",
    "        print(delta_u_ji)\n",
    "\n",
    "        mu_ij, sigma_ij = stats.norm.fit(delta_u_ij)\n",
    "        mu_ji, sigma_ji = stats.norm.fit(delta_u_ji) \n",
    "        print(sigma_ji,sigma_ji)\n",
    "        sigma = ( sigma_ij + sigma_ji ) / 2.0\n",
    "        sigmas.append(sigma)\n",
    "\n",
    "        delta_u_bins = np.arange(-15, 15., 0.2)\n",
    "        counts, bin_edges = np.histogram(delta_u_ij, bins=delta_u_bins)\n",
    "        counts = counts/counts.sum() # normalize\n",
    "        bin_centers = (bin_edges[0:-1] + bin_edges[1:])/2.0\n",
    "        \n",
    "        max_sigma = max(sigmas)\n",
    "        for i in range(len(sigmas)):\n",
    "            if (sigmas[i] == 0) or np.isnan(sigmas[i]):\n",
    "                sigmas[i] = max_sigma\n",
    "\n",
    "\n",
    "    return np.array(sigmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95f015f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def harmonic(x, xi):\n",
    "    kT=0.596\n",
    "    x = x * np.ones(len(xi))\n",
    "    return np.min(0.5*10*kT*(x-xi)**2)\n",
    "\n",
    "def sample(U, xinit,xi, nsteps, djump=0.5, xmin=0, xmax=11,\n",
    "           kT=0.596, nstride=1, nprint=10000, verbose=False):\n",
    "    x = xinit\n",
    "    energy=U(x,xi)\n",
    "    step = 0\n",
    "    accepted_steps = 0\n",
    "    traj = np.zeros(shape=(int(nsteps/nstride),1))\n",
    "    itraj = 0\n",
    "\n",
    "    # pre-calculate random numbers\n",
    "    r = np.random.random( nsteps )\n",
    "    s1 = np.random.random( nsteps )\n",
    "    ## Wang Landau ##\n",
    "    H = np.zeros(len(xi))\n",
    "    lngf = np.zeros(len(xi))\n",
    "    globef = np.zeros(len(traj))\n",
    "    Trans = np.zeros(shape=(len(xi),len(xi)))\n",
    "    f = 10\n",
    "    while step < nsteps:\n",
    "        prev_bin = np.argmin(np.abs(x*np.ones(len(xi)) - xi))\n",
    "        energy+=lngf[prev_bin]\n",
    "        xnew = x + djump*(2.0*s1[step]-1.0)\n",
    "        #ynew = y + djump*(2.0*s2[step]-1.0)\n",
    "        bin = np.argmin(np.abs(xnew*np.ones(len(xi)) - xi))\n",
    "        new_energy = U(xnew,xi)+lngf[bin]\n",
    "        # calculate Metropolis acceptance \n",
    "        accept = (r[step] < min(1, np.exp( -1.0*(new_energy-energy))))\n",
    "\n",
    "        # reject moves that bring x outside the range\n",
    "        accept = accept*(xnew>xmin)*(xnew<xmax)\n",
    "\n",
    "        if accept:\n",
    "            accepted_steps += 1\n",
    "            x = xnew\n",
    "            Trans[prev_bin,bin]+=1\n",
    "            print(f' Accepted {prev_bin} {bin}')\n",
    "            energy = U(x,xi)\n",
    "\n",
    "        if step%nstride == 0:\n",
    "            traj[itraj] = x\n",
    "            globef[itraj]= f\n",
    "            itraj += 1\n",
    "\n",
    "        if verbose:\n",
    "            if step%nprint == 0:\n",
    "                print('step', step, 'of', nsteps, ': x =', x, 'energy =', energy)\n",
    "\n",
    "        step += 1\n",
    "        H[prev_bin] += 1\n",
    "        lngf[prev_bin] += np.log10(f)\n",
    "        if np.min(H) > np.mean(H)*0.95:  # isFlat tests whether the histogram is flat (e.g. 95% flatness)\n",
    "            H[:] = 0\n",
    "            f *= 0.5  # Refine the f parameter\n",
    "        if np.log10(f) <= -2:\n",
    "            print(f'Simulation Converged in {itraj} steps')\n",
    "            break\n",
    "        acc_ratio = float(accepted_steps)/float(step)\n",
    "        print(acc_ratio)\n",
    "\n",
    "    return traj,H,lngf,globef,Trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf48d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "centers = [0,2,3.5,6.5,8,10]\n",
    "traj,H,lngf,globef,Trans = sample(harmonic,0,centers,int(1E5),nstride=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0e8d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(10,2))\n",
    "plt.plot(traj)\n",
    "#plt.xlim(1e3,1e7)\n",
    "#plt.xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23d08c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fcaf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def U(x,center):\n",
    "    kt = 300 * 1.38e-23\n",
    "    return 0.5 *10* 0.596*(x-center)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da977ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,3,figsize=(9,3))\n",
    "for i,x in enumerate(centers):\n",
    "    ax[0].plot(np.arange(-1,12,0.1),U(np.arange(-1,12,0.1),x))\n",
    "ax[0].set_ylim(-2,2.1)\n",
    "ax[0].set_yticks(np.arange(-2,2.1,1))\n",
    "ax[0].set_xticks([0,2.5,5,7.5,10])\n",
    "ax[1].bar(centers,H)\n",
    "ax[1].set_yscale('log')\n",
    "ax[2].plot(np.log10(globef))\n",
    "ax[2].set_yscale('log')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5a8276",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmas = estimate_sigmas(centers,Trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0680d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ffa9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../')\n",
    "from scripts.ee_tools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd0ba9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_sigmas(H, lambdas, plot_data=True):\n",
    "    \"\"\"Using as input the Delta_U_ij energies from the dhdl array, \n",
    "    estimate the standard deviations P(U_{i-->i+1}) for neighboring ensembles.\n",
    "    \n",
    "    RETURNS\n",
    "    sigmas   - a np.array() of standard deviations P(U_{i-->i+1}).\n",
    "    \"\"\"\n",
    "    \n",
    "    nlambdas = H.shape[0]\n",
    "    print('nlambdas', nlambdas)\n",
    "    \n",
    "    if plot_data:\n",
    "        plt.figure(figsize=(6, 80))\n",
    "\n",
    "    Delta_uij_values = []     \n",
    "    sigmas = []\n",
    "       \n",
    "    for j in range(nlambdas-1):\n",
    "    \n",
    "        ## transitions from state 0 to 1 or 1 to 2, or 2 to 3 .... \n",
    "\n",
    "        Ind = (lambdas == j)\n",
    "        delta_u_ij = H[Ind, j+1]       # forward delta_u only for neighbored ensembles\n",
    "\n",
    "        Ind2 = (lambdas == (j+1))\n",
    "        delta_u_ji = H[Ind2, j]       # forward delta_u only for neighbored ensembles\n",
    "\n",
    "        #print ('lambda index=', j)\n",
    "        #print ('delta_u_ij.shape=', delta_u_ij.shape)\n",
    "      \n",
    "        #Delta_uij_values.append(delta_u_ij)\n",
    "\n",
    "        ### VAV debug\n",
    "        print('Are any delta_u_ij values nan?')\n",
    "        print(delta_u_ij)\n",
    "        print('Are any delta_u_ji values nan?')\n",
    "        print(delta_u_ji)\n",
    "\n",
    "        mu_ij, sigma_ij = scipy.stats.norm.fit(delta_u_ij)\n",
    "        mu_ji, sigma_ji = scipy.stats.norm.fit(delta_u_ji) \n",
    "        \n",
    "        sigma = ( sigma_ij + sigma_ji ) / 2.0\n",
    "        sigmas.append(sigma)\n",
    "\n",
    "        delta_u_bins = np.arange(-15., 15., 0.2)\n",
    "        counts, bin_edges = np.histogram(delta_u_ij, bins=delta_u_bins)\n",
    "        counts = counts/counts.sum() # normalize\n",
    "        bin_centers = (bin_edges[0:-1] + bin_edges[1:])/2.0\n",
    "\n",
    "        if plot_data:\n",
    "            plt.subplot(nlambdas-1, 1, j+1)\n",
    "            plt.step(bin_centers, counts, label='$\\Delta u_{%d \\\\rightarrow %d} \\sigma$=%.2f'%(j,j+1,sigma))\n",
    "            #plt.xlabel('$\\Delta u_{%d \\\\rightarrow %d}$'%(j, j+1))\n",
    "            plt.legend(loc='best')\n",
    "        \n",
    "    if plot_data:\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    ## VAV: hot fix for non-sampled lambda (sigma = nan), or sampled only once (sigma = 0)\n",
    "    max_sigma = max(sigmas)\n",
    "    for i in range(len(sigmas)):\n",
    "        if (sigmas[i] == 0) or np.isnan(sigmas[i]):\n",
    "            sigmas[i] = max_sigma\n",
    "\n",
    "\n",
    "    return np.array(sigmas)\n",
    "\n",
    "def optimize_fep_lambdas(lambdas, H, make_plots=True, save_plots=False, verbose=True):\n",
    "    \"\"\"\n",
    "    DESCRIPTION\n",
    "        Optimize the lambda values for all intermediates\n",
    "        to minimize the total variance in P(\\Delta u_ij) for neighboring thermodynamic ensembles\n",
    "    RETURNS\n",
    "        fep-lambdas (their optimized values)\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    lambdas = lambdas\n",
    "    if verbose:\n",
    "        print('lambdas', lambdas)\n",
    "        print('lambdas.shape', lambdas.shape)\n",
    "\n",
    "\n",
    "    sigmas = estimate_sigmas(H, lambdas, plot_data=False)\n",
    "    if verbose:\n",
    "        print('sigmas.shape', sigmas.shape)\n",
    " \n",
    "    ### HOT FIX\n",
    "    ### If any of the sigma values are zero, then we know this is one of the cases where there are duplicate\n",
    "    ### fep-lambda\n",
    "\n",
    "    print('sigmas', sigmas)\n",
    "    indices_for_which_sigma_is_zero = np.where(sigmas < 0.0001)[0]\n",
    "    print('indices_for_which_sigma_is_zero', indices_for_which_sigma_is_zero)\n",
    "\n",
    "    # There should be only one such duplicate!\n",
    "    if len(indices_for_which_sigma_is_zero) == 1:\n",
    "        # For *THIS* particular data set we can see there is a problem:\n",
    "        # The i=49 --> i+1 = 50 lambdas are the same, resulting in a sigma of zero for that transition\n",
    "        # Let's remove it\n",
    "     \n",
    "        remove_index = indices_for_which_sigma_is_zero[0]\n",
    "        print('Removing DUPLICATE lambda index:', remove_index)\n",
    "        # print('sigmas', sigmas)\n",
    "        sigmas_list = sigmas.tolist()\n",
    "        sigmas_list.pop(remove_index)\n",
    "        sigmas = np.array(sigmas_list)\n",
    "        print('FIXED sigmas', sigmas)\n",
    "\n",
    "        print('lambdas',lambdas)\n",
    "        print('lambdas.shape',lambdas.shape)\n",
    "        lambdas_list = lambdas.tolist()\n",
    "        lambdas_list.pop(remove_index)\n",
    "        lambdas = np.array(lambdas_list)\n",
    "        print('FIXED lambdas',lambdas)\n",
    "        print('FIXED lambdas.shape',lambdas.shape)\n",
    "\n",
    "    elif len(indices_for_which_sigma_is_zero) > 1:\n",
    "        raise Exception(\"There are multiple zero sigma! Are there multiple duplicates in the lambda values?!\")\n",
    "\n",
    "    else:\n",
    "        print('There are no duplicate lambda')\n",
    "        pass\n",
    "\n",
    "\n",
    "    ### Lambda optimization\n",
    "\n",
    "    dx = sigmas                 #according to Vince's equation (VAV: k is set to 1)\n",
    "    \n",
    "    x_values = np.cumsum(dx)    # convert to a list of x values of separated harmonic potentials\n",
    "    x_values = np.array(np.concatenate([[0], x_values]))    # add a zero corresponding to lambda0 = 0.0\n",
    "    ## VAV: This zero needs to be included.  Why was this left out before?\n",
    "    print('x_values', x_values)\n",
    "\n",
    "\n",
    "    from scipy.interpolate import UnivariateSpline\n",
    "    from scipy.interpolate import interp1d\n",
    "\n",
    "    if make_plots:\n",
    "        plt.figure(figsize=(12,6))\n",
    "\n",
    "    lambda_values = lambdas #not inclduing the first one, lambda_0 \n",
    "\n",
    "    x_observed = lambda_values      #not inclduing the first one, lambda_0\n",
    "    y_observed = x_values\n",
    "\n",
    "    if make_plots:\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.plot(x_observed, y_observed, 'ro', label = 'data')\n",
    "        #plt.semilogy(x_observed, y_observed, 'ro', label = 'data')\n",
    "\n",
    "    #y_spl = CubicSpline(x_observed, y_observed)#, s=0,k=4)  \n",
    "    y_spl = UnivariateSpline(x_observed, y_observed, s=0, k=3)  \n",
    "    x_range = np.linspace(x_observed[0], x_observed[-1], 1000)\n",
    "\n",
    "\n",
    "    if make_plots:\n",
    "        plt.plot(x_range, y_spl(x_range), label=\"spline\")   # for UnivariateSpline\n",
    "        ## plt.plot(x_observed, y_spl(x_observed), label=\"spline\") # for CubicSpline\n",
    "        plt.legend()\n",
    "        plt.xlabel('lambda')\n",
    "        plt.ylabel('x values')\n",
    "\n",
    "        plt.subplot(1,2, 2)   #derivative plot\n",
    "\n",
    "    y_spl_1d = y_spl.derivative(n=1)    #n=1 , means the first order derivative\n",
    "    #print (y_spl_1d(x_observed))\n",
    "    # y_spl_1d = y_spl(x_observed, 1)  # first derivative of Cubic spline\n",
    "\n",
    "    if make_plots:\n",
    "        plt.plot(x_range, y_spl_1d(x_range), '-')\n",
    "        plt.plot(x_observed, y_spl_1d(x_observed), '.')\n",
    "        plt.ylabel('dx/dlambda')\n",
    "        \n",
    "        #plt.plot(x_observed, y_spl_1d, '.-', label='derivative')\n",
    "        plt.legend()\n",
    "        plt.xlabel('lambda')\n",
    "\n",
    "        if save_plots:\n",
    "            spline_pngfile = os.path.join(outdir, f'{outname}_splinefit.png') \n",
    "            plt.savefig(spline_pngfile)\n",
    "            print(f'Wrote: {spline_pngfile}')\n",
    "\n",
    "\n",
    "\n",
    "    # Let's try a steepest descent algorithm like the kind I wrote up in \"math-gradient-descent-2021-05-07.pdf\" -VAV\n",
    "\n",
    "    # run the algorithm some fixed number of steps, or until some tolerance is reached\n",
    "    nsteps = 100000\n",
    "    tol = 1e-7  # stop if the lambdas dont change within this tolerance\n",
    "\n",
    "    alpha = 1e-5  # gradient descent step size\n",
    "    max_del_lambda = 0.0001   # the minimization step limited to this as a maximum change\n",
    "\n",
    "    print_every = 2000\n",
    "    \n",
    "    nlambdas = len(lambda_values)\n",
    "    print('lambda_values', lambda_values)\n",
    "    old_lambdas = np.array(lambda_values)\n",
    "    traj_lambdas = np.zeros( (nlambdas,nsteps) )\n",
    "    for step in range(nsteps):\n",
    "\n",
    "        # store the trajectory of lambdas\n",
    "        traj_lambdas[:,step] = old_lambdas\n",
    "        if verbose:\n",
    "            print('step', step, old_lambdas)\n",
    "    \n",
    "        # perform a steepest descent step\n",
    "        new_lambdas = np.zeros( old_lambdas.shape )\n",
    "        del_lambdas = np.zeros( old_lambdas.shape )\n",
    "        del_lambdas[0] = 0.0   # fix the \\lambda = 0 endpoint\n",
    "        del_lambdas[nlambdas-1] = 0.0  # fix the \\lambda = 1 endpoint\n",
    "    \n",
    "        if False:  # do in a loop (SLOW!) \n",
    "            for i in range(1, (nlambdas-1)):\n",
    "                del_lambdas[i] = -1.0*alpha*2.0*y_spl_1d(old_lambdas[i])*( 2.0*y_spl(old_lambdas[i]) - y_spl(old_lambdas[i-1]) - y_spl(old_lambdas[i+1]))\n",
    "        else:   # do as a vector operation (FAST!) \n",
    "            y_all = y_spl(old_lambdas)\n",
    "            yh, yi, yj = y_all[0:nlambdas-2], y_all[1:nlambdas-1], y_all[2:nlambdas] \n",
    "            del_lambdas[1:nlambdas-1] = -1.0*alpha*2.0*y_spl_1d(old_lambdas[1:nlambdas-1])*( 2.0*yi - yh - yj)\n",
    "        if abs(np.max(del_lambdas)) > max_del_lambda:\n",
    "            del_lambdas[1:nlambdas-1] = del_lambdas[1:nlambdas-1]*max_del_lambda/np.max(del_lambdas)\n",
    "        new_lambdas = old_lambdas + del_lambdas\n",
    "        \n",
    "        # record the average change in the lambdas \n",
    "        del_lambdas = np.abs(old_lambdas - new_lambdas).mean()\n",
    "        if step % print_every == 0:\n",
    "            print('step', step, 'del_lambdas', del_lambdas)\n",
    "        if del_lambdas < tol:\n",
    "            print('Tolerance has been reached: del_lambdas =', del_lambdas, '< tol =', tol)\n",
    "            break\n",
    "        \n",
    "        old_lambdas = new_lambdas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a70e4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize_fep_lambdas(np.array(centers),H)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfd3623",
   "metadata": {},
   "source": [
    "# Derivation of the return time of a birth-death markov chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61db133",
   "metadata": {},
   "source": [
    "![image of birth-death chain](markov_chain.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809a405e",
   "metadata": {},
   "source": [
    "from https://scholarworks.calstate.edu/downloads/6395w909v pg28\n",
    "\n",
    "For brevity, let us assume a 4-step birth-dath chain, with transition matrix;\n",
    "\n",
    "$$ P=\n",
    "\\begin{pmatrix}\n",
    "a+b & c & 0 & 0\\\\\n",
    "a   & b & c & 0\\\\\n",
    "0   & a & b & c\\\\\n",
    "0   & 0 & a & c+b\\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "We assume that $a + b + c = 1$ and $0 < a, b, c < 1$.\n",
    "\n",
    "if H is even;\n",
    "\n",
    "$$ \n",
    "\\lambda_k = b-2\\sqrt(accos\\theta_k), k=0,1,2...\\frac{H}{2}-1\\\\\n",
    "\\lambda_k = b-2\\sqrt(accos\\theta_k), k=\\frac{H}{2}..H-1\\\\\n",
    "\\lambda_H = 1\\\\\n",
    "$$\n",
    "$$\\theta_k =   \\left\\{\n",
    "\\begin{array}{ll}\n",
    "      \\frac{(k+1)\\pi}{H+1}, k=0,1,2...\\frac{H}{2}-1\\\\\n",
    "      \\frac{(2k+2-H)\\pi}{2(H+1)}, k=\\frac{H}{2}..H-1\\\\\n",
    "\\end{array} \n",
    "\\right.\n",
    "$$\n",
    "\n",
    "if H is odd;\n",
    "$$\n",
    "\\lambda_k = b-2\\sqrt(accos\\theta_k), k=0,1,2...\\frac{H-3}{2}\\\\\\\n",
    "\\lambda_k = b-2\\sqrt(accos\\theta_k), k=\\frac{H-3}{2}..H-2\\\\\n",
    "\\lambda_{H-1} = b\n",
    "\\lambda_H = 1\n",
    "$$\n",
    "$$\\theta_k =   \\left\\{\n",
    "\\begin{array}{ll}\n",
    "      \\frac{(k+1)\\pi}{H+1}, k=0,1,2...\\frac{H-3}{2}\\\\\n",
    "      \\frac{(2k+2-H)\\pi}{2(H+1)}, k=\\frac{H-3}{2}..H-2\\\\\n",
    "\\end{array} \n",
    "\\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1169b04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
